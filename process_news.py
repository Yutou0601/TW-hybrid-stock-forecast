import pandas as pd
import numpy as np
import os
import torch
from transformers import AutoTokenizer, AutoModel
from tqdm import tqdm

# è¨­å®šè·¯å¾‘
INPUT_CSV = "data/raw/news/news_for_finbert.csv" 
OUTPUT_CSV = "data/processed/news_emb_hourly.csv"
# ğŸš€ ä¿®æ”¹ï¼šæ”¹ç”¨é‡‘èå°ˆç”¨ FinBERTï¼Œç¶­åº¦ç‚º 768
MODEL_NAME = "ProsusAI/finbert" 

def generate_embeddings():
    if not os.path.exists(INPUT_CSV):
        print(f"âŒ éŒ¯èª¤: æ‰¾ä¸åˆ°æª”æ¡ˆ {INPUT_CSV}")
        return

    print(f"1. è¼‰å…¥ FinBERT æ¨¡å‹: {MODEL_NAME}...")
    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)
    # ğŸš€ å¼·åˆ¶ä½¿ç”¨ safetensors é¿é–‹ torch.load æ¼æ´å ±éŒ¯
    model = AutoModel.from_pretrained(MODEL_NAME, use_safetensors=True).cuda()
    model.eval()

    print("2. è®€å–ä¸¦æ¸…æ´—æ–°èè³‡æ–™...")
    df = pd.read_csv(INPUT_CSV)
    df['datetime'] = pd.to_datetime(df['published_at']).dt.floor('H')
    # FinBERT å°æ¨™é¡Œé€šå¸¸æœ€æ•æ„Ÿ
    df['text'] = df['title'].fillna("") 
    
    grouped = df.groupby('datetime')
    hourly_vectors = {}
    
    print(f"3. è¨ˆç®— FinBERT å‘é‡ - è™•ç† {len(grouped)} å€‹åŸå§‹æ–°èå°æ™‚...")
    for dt, group in tqdm(grouped):
        texts = group['text'].astype(str).tolist()
        # ğŸš€ BoEC æ€æƒ³ï¼šå°è©²å°æ™‚å…§æ‰€æœ‰æ–°èé€²è¡Œ Embedding ä¸¦å–å¹³å‡è³ªå¿ƒ
        inputs = tokenizer(texts, return_tensors="pt", padding=True, truncation=True, max_length=128).to("cuda")
        
        with torch.no_grad():
            outputs = model(**inputs)
            # å– CLS token ä½œç‚ºç‰¹å¾µ (ç¶­åº¦ 768)
            embeddings = outputs.last_hidden_state[:, 0, :].cpu().numpy()
            mean_emb = np.mean(embeddings, axis=0)
            hourly_vectors[dt] = mean_emb

    print("4. åŸ·è¡Œæ™‚é–“è»¸å°é½Šèˆ‡æƒ…ç·’å»¶çºŒ...")
    emb_df = pd.DataFrame.from_dict(hourly_vectors, orient='index')
    emb_df.index = pd.to_datetime(emb_df.index)
    
    full_range = pd.date_range(start=emb_df.index.min(), end=emb_df.index.max(), freq='H')
    emb_df = emb_df.reindex(full_range)
    
    # æ¨¡æ“¬æ–°èæƒ…ç·’åœ¨ 8 å°æ™‚å…§æŒçºŒç™¼é…µ
    emb_df = emb_df.ffill(limit=8)
    emb_df = emb_df.fillna(0)
    
    emb_df.index.name = 'datetime'
    emb_df.columns = [f'emb_{i}' for i in range(emb_df.shape[1])]
    
    os.makedirs(os.path.dirname(OUTPUT_CSV), exist_ok=True)
    emb_df.to_csv(OUTPUT_CSV)
    print(f"âœ… æœ€çµ‚æ¨£æœ¬çŸ©é™£å½¢ç‹€: {emb_df.shape} (ç¶­åº¦å·²è½‰ç‚º 768)")

if __name__ == "__main__":
    generate_embeddings()